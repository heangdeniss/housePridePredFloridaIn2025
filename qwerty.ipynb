{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cde3e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Florida...\n",
      "Scraping FLorida...\n",
      "All properties saved to redfin_properties_all_cities.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text by removing extra whitespace and special characters\"\"\"\n",
    "    return ' '.join(text.strip().split()) if text else 'N/A'\n",
    "\n",
    "def scrape_redfin_properties(city_url, max_pages=100):\n",
    "    \"\"\"Scrape property listings from Redfin\"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\"\n",
    "    }\n",
    "    \n",
    "    properties = []\n",
    "    base_url = \"https://www.redfin.com\"\n",
    "    \n",
    "    for page in range(1, max_pages + 1):\n",
    "        try:\n",
    "            # Construct URL for pagination\n",
    "            page_url = f\"{city_url}/page-{page}\" if page > 1 else city_url\n",
    "            response = requests.get(page_url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            homecards = soup.find_all(\"div\", class_=\"HomeCardContainer\")\n",
    "            \n",
    "            if not homecards:\n",
    "                break\n",
    "                \n",
    "            for card in homecards:\n",
    "                try:\n",
    "                    # Extract link\n",
    "                    link_elem = card.find(\"a\", class_=\"link-and-anchor\")\n",
    "                    link = urljoin(base_url, link_elem[\"href\"]) if link_elem else 'N/A'\n",
    "                    \n",
    "                    # Extract price\n",
    "                    price_elem = card.find(\"span\", class_=\"bp-Homecard__Price--value\")\n",
    "                    price = clean_text(price_elem.text) if price_elem else 'N/A'\n",
    "                    \n",
    "                    # Extract beds\n",
    "                    beds_elem = card.find(\"span\", class_=\"bp-Homecard__Stats--beds\")\n",
    "                    beds = clean_text(beds_elem.text) if beds_elem else 'N/A'\n",
    "                    \n",
    "                    # Extract baths\n",
    "                    baths_elem = card.find(\"span\", class_=\"bp-Homecard__Stats--baths\")\n",
    "                    baths = clean_text(baths_elem.text) if baths_elem else 'N/A'\n",
    "                    \n",
    "                    # Extract square footage\n",
    "                    sqft_elem = card.find(\"span\", class_=\"bp-Homecard__Stats--sqft\")\n",
    "                    if not sqft_elem:\n",
    "                        # Alternative class names for square footage\n",
    "                        sqft_elem = card.find(\"span\", {\"data-rf-test-id\": \"homecard-stats-sqft\"})\n",
    "                    if not sqft_elem:\n",
    "                        # Try finding by text pattern\n",
    "                        stats_section = card.find(\"div\", class_=\"bp-Homecard__Stats\")\n",
    "                        if stats_section:\n",
    "                            stats_text = stats_section.get_text()\n",
    "                            import re\n",
    "                            sqft_match = re.search(r'(\\d{1,3}(?:,\\d{3})*)\\s*sq\\s*ft', stats_text, re.IGNORECASE)\n",
    "                            sqft = sqft_match.group(1) + \" sq ft\" if sqft_match else 'N/A'\n",
    "                        else:\n",
    "                            sqft = 'N/A'\n",
    "                    else:\n",
    "                        sqft = clean_text(sqft_elem.text)\n",
    "                    \n",
    "                    # Extract address\n",
    "                    address_elem = card.find(\"div\", class_=\"bp-Homecard__Address\")\n",
    "                    address = clean_text(address_elem.text) if address_elem else 'N/A'\n",
    "                    \n",
    "                    # Store property data - now including sqft\n",
    "                    property_data = {\n",
    "                        \"Price\": price,\n",
    "                        \"Beds\": beds,\n",
    "                        \"Baths\": baths,\n",
    "                        \"Sqft\": sqft,\n",
    "                        \"Address\": address,\n",
    "                        \"Link\": link\n",
    "                    }\n",
    "                    properties.append(property_data)\n",
    "                    \n",
    "                except AttributeError as e:\n",
    "                    print(f\"Error parsing property card: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            time.sleep(1)\n",
    "            \n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching page {page}: {e}\")\n",
    "            break\n",
    "    \n",
    "    return properties\n",
    "\n",
    "def save_to_csv(properties, filename=\"redfin_properties.csv\"):\n",
    "    \"\"\"Save properties to CSV file\"\"\"\n",
    "    with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"Price\", \"Beds\", \"Baths\", \"Sqft\", \"Address\", \"Link\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(properties)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    city_urls = {\n",
    "        'Florida': \"https://www.redfin.com/city/13655/FL/Orlando\",\n",
    "        \"FLorida\": \"https://www.redfin.com/city/18142/FL/Tampa\",\n",
    "        'Florida': \"https://www.redfin.com/county/442/FL/Broward-County\",\n",
    "        'Florida': \"https://www.redfin.com/city/11458/FL/Miami\",\n",
    "    }\n",
    "    all_properties = []\n",
    "    for city, url in city_urls.items():\n",
    "        print(f\"Scraping {city}...\")\n",
    "        properties = scrape_redfin_properties(url)\n",
    "        for prop in properties:\n",
    "            prop[\"City\"] = city\n",
    "        all_properties.extend(properties)\n",
    "    if all_properties:\n",
    "        with open(\"redfin_properties_all_cities.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=[\"City\", \"Price\", \"Beds\", \"Baths\", \"Sqft\", \"Address\", \"Link\"])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(all_properties)\n",
    "        print(\"All properties saved to redfin_properties_all_cities.csv\")\n",
    "    else:\n",
    "        print(\"No properties found for any city.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a27b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
